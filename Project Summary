  In this project I took Nashville housing data and molded it to be more usable for analysis.  I started by removing the excess info from the date column because it included 0:00 minutes and seconds for every column. (ALTER TABLE, CONVERT(), UPDATE) Next, I noticed that the data was missing addresses for certain properties. A pattern I noticed was that a duplicate ParcelID resulted in a duplicate property address.  Using this info I was able to populate the NULL values by self joining the table to itself on ParcelID where the UniqueID wasn’t equal and where PropertyAddress was NULL. Next, I wanted to split the PropertyAddress column into multiple columns so the data could be further analyzed by address and city.  The data had address and city separated by a “,” in every row so I used SUBSTRING(), CHARINDEX()  and LEN() to sort the data before the “,” into column PropertySplitAddress and all the data after “,” into column PropertySplitCity.  There was also another column named OwnerAddress, which included the state so I used PARSENAME(), which normally only works on periods, so I used REPLACE() to replace all the commas with periods.  Combining these two I created a new column PropertySplitState from OwnerAddress.  Once again I used ALTER table to add a new column with Nvarchar(255) then used UPDATE to set the new column up with PropertySplit data.  After that I noticed the SoldAsVacant column included 4 responses: yes, no, y, n. To standardize the data I used a case statement to turn Y and N into Yes and No.  Lastly, I removed duplicate rows using ROW_NUMBER() and Partition By. I chose Partition By ParcelID, PropertyAddress, SalePrice, SaleDate, LegalReference because if all of those were the exact same then it's reasonable to assume that it's a duplicate.  I could have removed any row that had the same uniqueID but I wanted to pretend it wasn’t there and instead use it as a reference.
